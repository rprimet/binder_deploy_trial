{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebooks pour Allgo\n",
    "[Allgo](https://allgo.inria.fr/) est un service qui offre une interface web pour des outils en ligne de commande. Il dispense ainsi les utilisateurs d'installer les programmes en question et offre la possibilité de cacher leur code source et modèles (pour les outils ayant besoin d'un entraînement). Il permet donc : \n",
    "* D'évaluer des outils de recherche (par des groupes de recherche et des industriels ?)\n",
    "* D'archiver un environnement d'exécution\n",
    "\n",
    "## Speads\n",
    "\n",
    "[Speads](https://allgo.inria.fr/app/speads) est un exemple d'application disponible sur Allgo. Speads segmente une conversation, identifie les locuteurs et tente de déterminer leur genre.\n",
    "\n",
    "Par exemple, en partant de cette conversation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"conv1.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient en sortie le tableau suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('conv1_speads.tsv') as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutôt qu'un simple tableau, on voudrait obtenir un graphique de ce type:\n",
    "![graphique](plot_1.png)\n",
    "\n",
    "Ici par exemple, on voit bien plus facilement qu'on a cinq locuteurs dont deux sont des hommes.\n",
    "\n",
    "Pour obtenir ce graphique, *et pour d'autres tâches d'analyse* -- il ne s'agit pas que de visualisation--, on a besoin d'un environnement plus puissant que l'UI d'Allgo, ce qui justifie le recours à un notebook type Jupyter. Par exemple, dans les données brutes, le genre du locuteur est mélangé avec son identifiant (comme dans `speaker4_F`), ce qui est problématique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparer les données\n",
    "\n",
    "Ici, on corrige le problème évoqué plus haut (genre et identifiant du locuteur mélangés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def preprocess_raw_speads_output(infile, outfile):\n",
    "    with open(outfile, 'w') as dest:\n",
    "        dest.write(\"ID\\tGender\\tStart\\tEnd\\n\")\n",
    "        with open(infile, 'r') as source:\n",
    "            reader = csv.reader(source, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                dest.write('{}\\t{}\\t{}\\t{}\\n'.format(row[0][:-2], row[0][-1:], row[1], row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_raw_speads_output(infile='conv1_speads.tsv', outfile='out/conv1_processed.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetons un oeil aux données après traitement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speaker0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.09000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speaker0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.65000</td>\n",
       "      <td>2.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speaker1</td>\n",
       "      <td>M</td>\n",
       "      <td>3.07000</td>\n",
       "      <td>4.56000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speaker2</td>\n",
       "      <td>M</td>\n",
       "      <td>7.35000</td>\n",
       "      <td>20.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speaker0</td>\n",
       "      <td>F</td>\n",
       "      <td>20.74000</td>\n",
       "      <td>23.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>speaker3</td>\n",
       "      <td>F</td>\n",
       "      <td>23.20000</td>\n",
       "      <td>24.73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>speaker0</td>\n",
       "      <td>F</td>\n",
       "      <td>24.73000</td>\n",
       "      <td>27.33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>speaker4</td>\n",
       "      <td>F</td>\n",
       "      <td>29.98000</td>\n",
       "      <td>41.44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>speaker3</td>\n",
       "      <td>F</td>\n",
       "      <td>41.44000</td>\n",
       "      <td>43.91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speaker1</td>\n",
       "      <td>M</td>\n",
       "      <td>46.53000</td>\n",
       "      <td>75.32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>speaker0</td>\n",
       "      <td>F</td>\n",
       "      <td>76.14000</td>\n",
       "      <td>78.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speaker0</td>\n",
       "      <td>F</td>\n",
       "      <td>79.98000</td>\n",
       "      <td>90.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>speaker4</td>\n",
       "      <td>F</td>\n",
       "      <td>90.58000</td>\n",
       "      <td>97.64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>speaker3</td>\n",
       "      <td>F</td>\n",
       "      <td>97.64000</td>\n",
       "      <td>129.35001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>speaker4</td>\n",
       "      <td>F</td>\n",
       "      <td>129.35001</td>\n",
       "      <td>134.85001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>speaker3</td>\n",
       "      <td>F</td>\n",
       "      <td>134.85001</td>\n",
       "      <td>152.25999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>speaker4</td>\n",
       "      <td>F</td>\n",
       "      <td>152.25999</td>\n",
       "      <td>156.28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Gender      Start        End\n",
       "0   speaker0      F    0.00000    1.09000\n",
       "1   speaker0      F    1.65000    2.60000\n",
       "2   speaker1      M    3.07000    4.56000\n",
       "3   speaker2      M    7.35000   20.74000\n",
       "4   speaker0      F   20.74000   23.20000\n",
       "5   speaker3      F   23.20000   24.73000\n",
       "6   speaker0      F   24.73000   27.33000\n",
       "7   speaker4      F   29.98000   41.44000\n",
       "8   speaker3      F   41.44000   43.91000\n",
       "9   speaker1      M   46.53000   75.32000\n",
       "10  speaker0      F   76.14000   78.75000\n",
       "11  speaker0      F   79.98000   90.58000\n",
       "12  speaker4      F   90.58000   97.64000\n",
       "13  speaker3      F   97.64000  129.35001\n",
       "14  speaker4      F  129.35001  134.85001\n",
       "15  speaker3      F  134.85001  152.25999\n",
       "16  speaker4      F  152.25999  156.28000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('out/conv1_processed.tsv', sep='\\t')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser la conversation avec Vega-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vega\n",
    "vega.VegaLite({\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.json\",\n",
    "  \"description\": \"Conversation timeline\",\n",
    "  \"mark\": \"bar\",\n",
    "  \"encoding\": {\n",
    "    \"y\": {\"field\": \"ID\", \"type\": \"nominal\"},\n",
    "    \"x\": {\"field\": \"Start\", \"type\": \"quantitative\"},\n",
    "    \"x2\": {\"field\": \"End\", \"type\": \"quantitative\"},\n",
    "    \"color\": {\"field\": \"Gender\", \n",
    "              \"type\": \"nominal\",\n",
    "              \"scale\": {\n",
    "                \"domain\": [\"F\",\"M\"],\n",
    "                 \"range\": [\"#ff99ff\",\"#4169e1\"]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "},\n",
    "data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... ce qui n'est pas le résultat attendu.\n",
    "\n",
    "* Première surprise : pas de support stable de Vega-Lite dans JupyterLab (alors qu'il s'agit d'un plugin *core*). Au 3 octobre 2017, la bibliothèque python nécessaire n'est pas disponible par `pip` (et un build manuel échoue).\n",
    "  - Donc, on ne peut embarquer la visualisation précédente que dans Jupyter Classic, à moins d'utiliser des appels bas niveau ? \n",
    "* Deuxième surprise : dans Jupyter Classic, le plugin Vega-Lite ne permet pas les visualisations superposées (*layered*). J'ai ouvert [un ticket](https://github.com/altair-viz/jupyter_vega/issues/38) à ce sujet.\n",
    "* Apparemment, la version de vega-lite utilisée dans le plugin *core* est la v1 (la version actuelle est la v2).\n",
    "\n",
    "On peut contourner ce problème avec une approche bas niveau (qu'on aimerait quand même éviter...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v1+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.json",
       "data": {
        "values": [
         {
          "End": 1.09,
          "Gender": "F",
          "ID": "speaker0",
          "Start": 0
         },
         {
          "End": 2.6,
          "Gender": "F",
          "ID": "speaker0",
          "Start": 1.65
         },
         {
          "End": 4.56,
          "Gender": "M",
          "ID": "speaker1",
          "Start": 3.07
         },
         {
          "End": 20.74,
          "Gender": "M",
          "ID": "speaker2",
          "Start": 7.35
         },
         {
          "End": 23.2,
          "Gender": "F",
          "ID": "speaker0",
          "Start": 20.74
         },
         {
          "End": 24.73,
          "Gender": "F",
          "ID": "speaker3",
          "Start": 23.2
         },
         {
          "End": 27.33,
          "Gender": "F",
          "ID": "speaker0",
          "Start": 24.73
         },
         {
          "End": 41.44,
          "Gender": "F",
          "ID": "speaker4",
          "Start": 29.98
         },
         {
          "End": 43.91,
          "Gender": "F",
          "ID": "speaker3",
          "Start": 41.44
         },
         {
          "End": 75.32,
          "Gender": "M",
          "ID": "speaker1",
          "Start": 46.53
         },
         {
          "End": 78.75,
          "Gender": "F",
          "ID": "speaker0",
          "Start": 76.14
         },
         {
          "End": 90.58,
          "Gender": "F",
          "ID": "speaker0",
          "Start": 79.98
         },
         {
          "End": 97.64,
          "Gender": "F",
          "ID": "speaker4",
          "Start": 90.58
         },
         {
          "End": 129.35001,
          "Gender": "F",
          "ID": "speaker3",
          "Start": 97.64
         },
         {
          "End": 134.85001,
          "Gender": "F",
          "ID": "speaker4",
          "Start": 129.35001
         },
         {
          "End": 152.25999,
          "Gender": "F",
          "ID": "speaker3",
          "Start": 134.85001
         },
         {
          "End": 156.28,
          "Gender": "F",
          "ID": "speaker4",
          "Start": 152.25999
         }
        ]
       },
       "description": "Conversation timeline",
       "encoding": {
        "color": {
         "field": "Gender",
         "scale": {
          "domain": [
           "F",
           "M"
          ],
          "range": [
           "#ff99ff",
           "#4169e1"
          ]
         },
         "type": "nominal"
        },
        "x": {
         "field": "Start",
         "type": "quantitative"
        },
        "x2": {
         "field": "End",
         "type": "quantitative"
        },
        "y": {
         "field": "ID",
         "type": "nominal"
        }
       },
       "mark": "bar"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_static_conversation(dataframe):\n",
    "  from IPython.display import display\n",
    "  import json\n",
    "  bundle_contents = {\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.json\",\n",
    "  \"description\": \"Conversation timeline\",\n",
    "  \"data\": {\n",
    "    \"values\": json.loads(dataframe.to_json(orient='records'))\n",
    "  },\n",
    "  \"mark\": \"bar\",\n",
    "  \"encoding\": {\n",
    "    \"y\": {\"field\": \"ID\", \"type\": \"nominal\"},\n",
    "    \"x\": {\"field\": \"Start\", \"type\": \"quantitative\"},\n",
    "    \"x2\": {\"field\": \"End\", \"type\": \"quantitative\"},\n",
    "    \"color\": {\"field\": \"Gender\", \n",
    "              \"type\": \"nominal\",\n",
    "              \"scale\": {\n",
    "                \"domain\": [\"F\",\"M\"],\n",
    "                 \"range\": [\"#ff99ff\",\"#4169e1\"]\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "  mime_bundle = {'application/vnd.vegalite.v1+json': bundle_contents}\n",
    "  display(mime_bundle, raw=True)\n",
    "\n",
    "display_static_conversation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(on note que vegalite a une version de retard...)\n",
    "\n",
    "## Montrer la tête de lecture sur la visualisation\n",
    "\n",
    "Au-delà de la première visualisation (utile mais statique), on pourrait aller plus loin en synchronisant la lecture de l'extrait avec le temps sur le graphique. Cela permettrait de comprendre mieux le comportement de l'outil et les données générées. Par exemple:\n",
    "* La longueur de la conversation décrite est-elle bien celle de l'extrait audio ?\n",
    "* Les temps de début et de fin sont-ils les bons ?\n",
    "* L'outil détecte-t-il un même locuteur sous deux identifiants différents, ou le contraire (moins de locuteurs trouvés que dans la conversation) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tape_vis(id, data, tape_pos):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un plugin dédié (option lourde)\n",
    "\n",
    "On devrait pouvoir contourner ces problèmes en écrivant un plugin dédié. C'est une approche lourde et idéalement, on ne devrait pas avoir à y recourir pour un prototype (pour lequel on utiliserait plutôt [cette approche](https://gist.github.com/minrk/1a1e56a611f1ff1e2645f733bdd0e381) pour lier deux composants) ou un tutoriel, mais seulement pour les cas où un besoin affirmé existe. \n",
    "\n",
    "Un plugin permet de garder toute l'interaction dans le navigateur et d'éviter les allers-retours entre le kernel et le navigateur, ainsi que d'avoir une interaction aussi personnalisée que nécessaire.\n",
    "\n",
    "Le plugin est visible dans le dossier `jupyterlab_speads`. Ici on se contente de montrer la partie python minimale du code (presque tout est fait côté client) et le résultat. *En principe, la partie Python écrite ici devrait être packagée séparément et on devrait seulement invoquer `interactive_conversation()`*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "def make_data_url(filename):\n",
    "    import base64\n",
    "    import mimetypes\n",
    "    with open(filename, 'rb') as f:\n",
    "        return \"data:{};base64,{}\".format(mimetypes.guess_type(filename)[0], base64.b64encode(f.read()).decode('ascii'))\n",
    "    \n",
    "def make_vis_spec(dataframe):\n",
    "    import json\n",
    "    return {\n",
    "    \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.json\",\n",
    "    \"layer\": [\n",
    "        {\n",
    "            \"description\": \"Conversation timeline\",\n",
    "            \"data\": {\n",
    "                \"values\": json.loads(dataframe.to_json(orient='records'))\n",
    "            },\n",
    "            \"mark\": \"bar\",\n",
    "            \"encoding\": {\n",
    "                \"y\": {\n",
    "                    \"field\": \"ID\",\n",
    "                    \"type\": \"nominal\"\n",
    "                },\n",
    "                \"x\": {\n",
    "                    \"field\": \"Start\",\n",
    "                    \"type\": \"quantitative\"\n",
    "                },\n",
    "                \"x2\": {\n",
    "                    \"field\": \"End\",\n",
    "                    \"type\": \"quantitative\"\n",
    "                },\n",
    "                \"color\": {\n",
    "                    \"field\": \"Gender\",\n",
    "                    \"type\": \"nominal\",\n",
    "                    \"scale\": {\n",
    "                        \"domain\": [\n",
    "                            \"F\",\n",
    "                            \"M\"\n",
    "                        ],\n",
    "                        \"range\": [\n",
    "                            \"#ff99ff\",\n",
    "                            \"#4169e1\"\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"description\": \"Tape head\",\n",
    "            \"data\": {\n",
    "                \"values\": [\n",
    "                    {\n",
    "                        \"timepos\": 42\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"mark\": \"rule\",\n",
    "            \"encoding\": {\n",
    "                \"x\": {\n",
    "                    \"field\": \"timepos\",\n",
    "                    \"type\": \"quantitative\"\n",
    "                },\n",
    "                \"size\": {\n",
    "                    \"value\": 2\n",
    "                },\n",
    "                \"color\": {\n",
    "                    \"value\": \"#22aa12\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def interactive_conversation(soundfile_path, dataframe):\n",
    "    from IPython.display import display\n",
    "    bundle_contents = {\n",
    "        \"audio_data\": make_data_url(soundfile_path),\n",
    "        \"vis_spec\": make_vis_spec(dataframe)\n",
    "    }\n",
    "    bundle = {\"application/vnd.speads+json\": bundle_contents}\n",
    "    display(bundle, raw=True)\n",
    "\n",
    "interactive_conversation('conv1.mp3', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche entièrement web (sans notebook)\n",
    "\n",
    "Pour montrer le résultat attendu, voir l'exemple [ici](web_only/index.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "En préparant ce carnet, mon idée est de :\n",
    "* Proposer un scenario / cadre de projet collaboratif pour le SED autour d'Allgo (qui avait été évoqué en réunion)\n",
    "  - Autrement dit, de proposer une UI plus adaptée pour un outil hébergé sur Allgo, en proposant un déploiement aussi simple que possible ; idéalement, rien à faire du côté d'Allgo, et de notre côté, le carnet serait déployé via [Binder](https://beta.mybinder.org).\n",
    "* Évaluer l'état actuel d'avancement de JupyterLab sur un cas simple mais pas trivial\n",
    "* Évaluer la difficulté de proposer une visualisation interactive non-native (ici, la synchro) avec Jupyter/JupyterLab et la qualité du résultat obtenu.\n",
    "\n",
    "Si un tel environnement est proposé, il doit être assez souple; par exemple permettre de choisir la configuration du serveur Jupyter / JupyterLab (`IOPub data rate exceeded.`). Est-ce le cas avec Binder ?\n",
    "\n",
    "Remarques \n",
    "\n",
    "* Pour l'instant, maintenir un plugin JupyterLab pour une démo n'est pour moi **pas judicieux** (API toujours en évolution, lourdeur de l'approche). Mais cela pourrait être envisageable après la sortie de JupyterLab 1.0, pour des projets où il y a un besoin récurrent.\n",
    "* Une critique de Jupyter [ici](http://opiateforthemass.es/articles/why-i-dont-like-jupyter-fka-ipython-notebook/).\n",
    "\n",
    "## Annexe: nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean():\n",
    "    import os\n",
    "    os.system('rm out/*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
